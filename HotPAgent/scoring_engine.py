from typing import List
import pandas as pd
from models import HotTopic, LLMAnalysis, EnrichedTopic
from config import Config
from loguru import logger


class ScoringEngine:
    """çƒ­åº¦ç»¼åˆè¯„åˆ†å¼•æ“"""
    
    def __init__(self):
        self.weight_heat = Config.WEIGHT_HEAT
        self.weight_discussion = Config.WEIGHT_DISCUSSION
        self.weight_llm = Config.WEIGHT_LLM
    
    def normalize(self, values: List) -> List[float]:
        """
        å½’ä¸€åŒ–åˆ° 0-100 åŒºé—´
        
        Args:
            values: åŸå§‹æ•°å€¼åˆ—è¡¨
            
        Returns:
            å½’ä¸€åŒ–åçš„åˆ—è¡¨
        """
        if not values or max(values) == 0:
            return [0.0] * len(values)
        
        min_val = min(values)
        max_val = max(values)
        
        if max_val == min_val:
            return [50.0] * len(values)
        
        return [(v - min_val) / (max_val - min_val) * 100 for v in values]
    
    def calculate_scores(
        self, 
        topics: List[HotTopic], 
        analyses: List[LLMAnalysis]
    ) -> List[EnrichedTopic]:
        """
        è®¡ç®—ç»¼åˆè¯„åˆ†
        
        Args:
            topics: åŸå§‹è¯é¢˜åˆ—è¡¨
            analyses: LLMåˆ†æç»“æœåˆ—è¡¨
            
        Returns:
            ç»è¿‡è¯„åˆ†çš„è¯é¢˜åˆ—è¡¨
        """
        if len(topics) != len(analyses):
            logger.error("è¯é¢˜æ•°é‡ä¸åˆ†æç»“æœæ•°é‡ä¸åŒ¹é…")
            return []
        
        # æå–æ‰€æœ‰çƒ­åº¦å€¼å’Œè®¨è®ºé‡
        heat_scores = [t.heat_score for t in topics]
        discussion_volumes = [t.discussion_volume or 0 for t in topics]
        
        # å½’ä¸€åŒ–
        normalized_heats = self.normalize(heat_scores)
        normalized_discussions = self.normalize(discussion_volumes)
        
        enriched_topics = []
        
        for i, (topic, analysis) in enumerate(zip(topics, analyses)):
            # è®¡ç®—ç»¼åˆè¯„åˆ†
            total_score = (
                normalized_heats[i] * self.weight_heat +
                normalized_discussions[i] * self.weight_discussion +
                (analysis.potential_score * 10) * self.weight_llm
            )
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºçˆ†ç‚¹è¯é¢˜
            is_breakout = total_score >= Config.SCORE_THRESHOLD
            
            enriched_topic = EnrichedTopic(
                platform=topic.platform,
                title=topic.title,
                heat_score=topic.heat_score,
                link=topic.link,
                discussion_volume=topic.discussion_volume,
                category=topic.category,
                llm_analysis=analysis,
                normalized_heat=round(normalized_heats[i], 2),
                normalized_discussion=round(normalized_discussions[i], 2),
                total_score=round(total_score, 2),
                is_breakout=is_breakout
            )
            
            enriched_topics.append(enriched_topic)
            
            if is_breakout:
                logger.success(
                    f"ğŸ”¥ å‘ç°çˆ†ç‚¹è¯é¢˜: {topic.title} "
                    f"(ç»¼åˆè¯„åˆ†: {total_score:.2f}, LLMæ½œåŠ›åˆ†: {analysis.potential_score})"
                )
        
        # æŒ‰è¯„åˆ†æ’åº
        enriched_topics.sort(key=lambda x: x.total_score, reverse=True)
        
        return enriched_topics
    
    def get_statistics(self, topics: List[EnrichedTopic]) -> dict:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            topics: è¯„åˆ†åçš„è¯é¢˜åˆ—è¡¨
            
        Returns:
            ç»Ÿè®¡å­—å…¸
        """
        df = pd.DataFrame([t.dict() for t in topics])
        
        # ä» llm_analysis ä¸­æå–è¯é¢˜æ€§è´¨ï¼Œå…¼å®¹ dict å’Œå¯¹è±¡ä¸¤ç§æƒ…å†µ
        nature_series = df["llm_analysis"].apply(
            lambda x: (
                x.get("topic_nature", "æœªçŸ¥")
                if isinstance(x, dict)
                else getattr(x, "topic_nature", "æœªçŸ¥")
            )
        )
        
        stats = {
            "total_count": len(topics),
            "breakout_count": sum(1 for t in topics if t.is_breakout),
            "avg_score": df['total_score'].mean(),
            "max_score": df['total_score'].max(),
            "min_score": df['total_score'].min(),
            "platform_distribution": df['platform'].value_counts().to_dict(),
            "nature_distribution": nature_series.value_counts().to_dict()
        }
        
        return stats
